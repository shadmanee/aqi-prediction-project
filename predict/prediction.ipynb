{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e71ecfa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f6f6c7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data for the single row\n",
    "data = {\n",
    "    'date': ['2025-08-26 12:00:00'],\n",
    "    'city': ['dhaka'],\n",
    "    'pm10': [22.5],\n",
    "    'pm2_5': [20.1],\n",
    "    'carbon_monoxide': [365.0],\n",
    "    'nitrogen_dioxide': [19.8],\n",
    "    'sulphur_dioxide': [13.5],\n",
    "    'ozone': [31.0],\n",
    "    'uv_index_clear_sky': [0.4],\n",
    "    'uv_index': [0.25],\n",
    "    'dust': [1.2],\n",
    "    'aerosol_optical_depth': [0.41]\n",
    "}\n",
    "\n",
    "# Create the DataFrame\n",
    "prediction_df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "184adb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_cluster(df):\n",
    "    clusterer = joblib.load(\"../models/clustering.joblib\")\n",
    "    scaler = joblib.load(\"../encoder/scaling.joblib\")\n",
    "    numeric_columns = df.select_dtypes(\"number\").columns\n",
    "    X = scaler.transform(df[[col for col in numeric_columns if col != \"us_aqi\"]].values)\n",
    "    df[\"cluster\"] = clusterer.predict(X)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "dda5892c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(df):\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "    df['hour_sin'] = np.sin(2 * np.pi * df['date'].dt.hour / 24.0)\n",
    "    df['hour_cos'] = np.cos(2 * np.pi * df['date'].dt.hour / 24.0)\n",
    "    df['month_sin'] = np.sin(2 * np.pi * df['date'].dt.month / 12.0)\n",
    "    df['month_cos'] = np.cos(2 * np.pi * df['date'].dt.month / 12.0)\n",
    "    df['day_of_week'] = df['date'].dt.dayofweek # Monday=0, Sunday=6\n",
    "    df['year'] = df['date'].dt.year\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "28ffd4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_encoding(df):\n",
    "    label_encoder = joblib.load(\"../encoder/city_encoder.joblib\")\n",
    "    df[\"city_encoded\"] = label_encoder.transform(df[\"city\"])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "916568ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_feature_selection(model):\n",
    "    return model == \"mlp_lstm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4ea24740",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_metrics(y_test, y_pred):\n",
    "    from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, mean_absolute_percentage_error\n",
    "\n",
    "    # 1. Mean Squared Error (MSE)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
    "\n",
    "    # 2. Root Mean Squared Error (RMSE)\n",
    "    rmse = np.sqrt(mse)\n",
    "    print(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\")\n",
    "\n",
    "    # 3. R-squared (R²)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    print(f\"R-squared (R²): {r2:.2f}\")\n",
    "\n",
    "    # 4. Mean Absolute Error (MAE) - NEW\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "\n",
    "    # 5. Mean Absolute Percentage Error (MAPE) - NEW\n",
    "    mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "    print(f\"Mean Absolute Percentage Error (MAPE): {mape:.2%}\") # Formats as a percentage\n",
    "\n",
    "    return mse, rmse, r2, mae, mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "63f68dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_mlp_lstm_models(model, df):\n",
    "    X_test = df[[col for col in df.columns if col not in [\"date\", \"us_aqi\", \"city\"]]]\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2f85d72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(prediction_df):\n",
    "    df_with_cluster = assign_cluster(df=prediction_df)\n",
    "    feature_engineered_df = feature_engineering(df=df_with_cluster)\n",
    "    label_encoded_df = label_encoding(df=feature_engineered_df)\n",
    "\n",
    "    print(f\"Select which of the following models you want to use for prediction:\\n[1] Linear Regression\\n[2] Decision Tree\\n[3] K-Nearest Neighbor\\n[4] Random Forest\\n[5] eXtreme Gradient Boosting\\n[6] MLP-LSTM\\n{\"-\"*30}\\n* 'q' to end selection\\n\")\n",
    "    model_names = []\n",
    "    while len(model_names) < 6:\n",
    "        model_name = str(input(\"Enter: \"))\n",
    "        if model_name == \"1\":\n",
    "            model_names.append(\"linear_regressor\")\n",
    "        elif model_name == \"2\":\n",
    "            model_names.append(\"decision_tree_regressor\")\n",
    "        elif model_name == \"3\":\n",
    "            model_names.append(\"knn_regressor\")\n",
    "        elif model_name == \"4\":\n",
    "            model_names.append(\"random_forest_regressor\")\n",
    "        elif model_name == \"5\":\n",
    "            model_names.append(\"xgb_regressor\")\n",
    "        elif model_name == \"6\":\n",
    "            model_names.append(\"mlp_lstm\")\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    print(\"Predicting using models: \", model_names)\n",
    "\n",
    "    for model_name in model_names:\n",
    "        model = joblib.load(f\"../models/{model_name}.joblib\")\n",
    "        if perform_feature_selection(model_name):\n",
    "            pass\n",
    "        else:\n",
    "            predicted_aqi = non_mlp_lstm_models(model, label_encoded_df)\n",
    "            print(f\"Predicted AQI ({model_name}): {predicted_aqi[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "989d70da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select which of the following models you want to use for prediction:\n",
      "[1] Linear Regression\n",
      "[2] Decision Tree\n",
      "[3] K-Nearest Neighbor\n",
      "[4] Random Forest\n",
      "[5] eXtreme Gradient Boosting\n",
      "[6] MLP-LSTM\n",
      "------------------------------\n",
      "* 'q' to end selection\n",
      "\n",
      "Predicting using models:  ['knn_regressor', 'random_forest_regressor', 'xgb_regressor']\n",
      "Predicted AQI (knn_regressor): 78.71454\n",
      "Predicted AQI (random_forest_regressor): 70.73243244\n",
      "Predicted AQI (xgb_regressor): 63.82838439941406\n"
     ]
    }
   ],
   "source": [
    "main(prediction_df=prediction_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c9f1e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ace3316",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0200058",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd40d3ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
